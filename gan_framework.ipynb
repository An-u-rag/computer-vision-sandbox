{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/An-u-rag/computer-vision-sandbox/blob/main/gan_framework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZLDpr0NC4HG2"
      },
      "outputs": [],
      "source": [
        "#@title import libraries\n",
        "\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title load dataset\n",
        "\n",
        "batch_size = 100\n",
        "#TODO: define transform that turns images to torch tensors and normalizes them to (-1, 1)\n",
        "#Hint: use transforms.ToTensor() and transforms.Normalize()\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5), std=(0.5))\n",
        "])\n",
        "\n",
        "\n",
        "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "\n",
        "trainloader = DataLoader(mnist_trainset, batch_size = batch_size, num_workers = 0, shuffle=True)"
      ],
      "metadata": {
        "id": "_fJ2P54F4m6F"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define generator model\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, noise_dim, out_dim):\n",
        "    super(Generator, self).__init__()\n",
        "    #noise_dim: dimension of input noise vector\n",
        "    #out_dim: dimenstion of output image in our case 28 * 28\n",
        "\n",
        "    #TODO: define fully connected network with dims: noise_dim -> 256 -> 512 -> 512 -> out_dim\n",
        "    self.fc1 = nn.Linear(noise_dim, 256)\n",
        "    self.fc2 = nn.Linear(256, 512)\n",
        "    self.fc3 = nn.Linear(512, 512)\n",
        "    self.fc4 = nn.Linear(512, out_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.leaky_relu(self.fc1(x), negative_slope = 0.2)\n",
        "    out = F.leaky_relu(self.fc2(out), negative_slope = 0.2)\n",
        "    out = F.leaky_relu(self.fc3(out), negative_slope = 0.2)\n",
        "    out = torch.tanh(self.fc4(out))\n",
        "\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "U9KcNnjs49Di"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G = Generator(100, 28 * 28)\n",
        "print(G)"
      ],
      "metadata": {
        "id": "dD-bNFse7kVI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2761182c-e769-4da5-b308-2d8baca6b408"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator(\n",
            "  (fc1): Linear(in_features=100, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
            "  (fc3): Linear(in_features=512, out_features=512, bias=True)\n",
            "  (fc4): Linear(in_features=512, out_features=784, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define discriminator model\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, image_dim):\n",
        "    super(Discriminator, self).__init__()\n",
        "    #image_dim: dimension of input image. in our case 28 * 28\n",
        "    #TODO define linear layers with dims image_dim -> 256 -> 128 -> 64 -> 1\n",
        "    self.fc1 = nn.Linear(image_dim, 256)\n",
        "    self.fc2 = nn.Linear(256, 128)\n",
        "    self.fc3 = nn.Linear(128, 64)\n",
        "    self.fc4 = nn.Linear(64, 1)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "     out = F.leaky_relu(self.fc1(x), negative_slope = 0.2)\n",
        "     out = F.dropout(out, p=0.3)\n",
        "     out = F.leaky_relu(self.fc2(out), negative_slope = 0.2)\n",
        "     out = F.dropout(out, p=0.3)\n",
        "     out = F.leaky_relu(self.fc3(out), negative_slope = 0.2)\n",
        "     out = F.dropout(out, p=0.3)\n",
        "     out = torch.sigmoid(self.fc4(out))\n",
        "     return out"
      ],
      "metadata": {
        "id": "sl8GjZVd7G5s"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D = Discriminator(28 * 28)\n",
        "print(D)"
      ],
      "metadata": {
        "id": "sKKJ4Ngq7vA8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "126012d5-0792-4be1-fb92-da943fc0d773"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator(\n",
            "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc4): Linear(in_features=64, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title training\n",
        "\n",
        "lr = 0.0002 #learning rate\n",
        "nepochs = 10 #number of training epochs\n",
        "noise_dim = 100 #dimension of input noise vector\n",
        "\n",
        "class Trainer:\n",
        "  def __init__(self):\n",
        "    self.G = Generator(noise_dim = noise_dim, out_dim = 28 * 28)\n",
        "    self.D = Discriminator(image_dim = 28 * 28)\n",
        "\n",
        "    #TODO: define optimizers. one for generator and one for discriminator\n",
        "    #Hint: use torch.optim.Adam()\n",
        "\n",
        "    self.G_optimizer = torch.optim.Adam(self.G.parameters(), lr=lr)\n",
        "    self.D_optimizer = torch.optim.Adam(self.D.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "    #define loss function\n",
        "    self.criterion = nn.BCELoss()\n",
        "\n",
        "    self.eval_freq = 1\n",
        "    self.fig_dir = './figs'\n",
        "    os.makedirs(self.fig_dir, exist_ok = True)\n",
        "\n",
        "  def run(self):\n",
        "    for e in range(1, nepochs + 1):\n",
        "      if e % self.eval_freq == 0:\n",
        "        self.eval_step(e)\n",
        "      self.train_step(e)\n",
        "\n",
        "  def train_step(self, epoch):\n",
        "    self.G.train()\n",
        "    self.D.train()\n",
        "    pbar = tqdm(trainloader)\n",
        "    for i, data in enumerate(pbar):\n",
        "      real_data, _ = data\n",
        "      real_data = real_data\n",
        "      D_loss = self.train_D(real_data)\n",
        "      G_loss = self.train_G()\n",
        "\n",
        "      \n",
        "\n",
        "      pbar.set_description(\"Epoch: {}, G_loss = {:.4f}, D_loss = {:.4f}\".format(epoch, G_loss, D_loss))\n",
        "\n",
        "  def train_D(self, real_data):\n",
        "    self.D_optimizer.zero_grad()\n",
        "    D_loss = 0.\n",
        "    #TODO: train discriminator\n",
        "    #real data: a batch of real data with shape(batch_size, 1, 28, 28)\n",
        "    #1. feed real data to D\n",
        "    #2. generate labels for real data (shoud be all ones). Hint: use torch.ones()\n",
        "    #3. compute loss for real data\n",
        "    #4. generate noise. Hint: use torch.randn()\n",
        "    #5. feed noise to G to get fake data\n",
        "    #6. feed fake data to D\n",
        "    #7. generate labels for fake data (shoud be all zeros). Hint: use torch.zeros()\n",
        "    #8. compute loss for fake data\n",
        "    #9. add losses and optimize D\n",
        "    real_data = real_data.reshape(batch_size, -1)\n",
        "    D_real = self.D(real_data)\n",
        "    real_labels = torch.ones((batch_size, 1))\n",
        "    real_loss = self.criterion(D_real, real_labels)\n",
        "\n",
        "    noisy_data = torch.randn((batch_size, noise_dim))\n",
        "    fake_data = self.G(noisy_data)\n",
        "    D_fake = self.D(fake_data)\n",
        "    fake_labels = torch.zeros((batch_size, 1))\n",
        "    fake_loss = self.criterion(D_fake, fake_labels)\n",
        "    D_loss = real_loss + fake_loss\n",
        "    D_loss.backward()\n",
        "    self.D_optimizer.step()\n",
        "    return D_loss\n",
        "\n",
        "  def train_G(self):\n",
        "    self.G_optimizer.zero_grad()\n",
        "    G_loss = 0.\n",
        "    #TODO: train generator\n",
        "    #1. generate noise. Hint: use torch.randn()\n",
        "    #2. feed noise to G to get fake data\n",
        "    #3. feed fake data to D\n",
        "    #4. generate labels for fake data (shoud be all ones) (why?). Hint: use torch.zerooness()\n",
        "    #5. compute loss for fake data\n",
        "    #6. optimize generator\n",
        "    noise = torch.randn((batch_size, noise_dim))\n",
        "    D_fake_data = self.G(noise)\n",
        "    labels = torch.ones((batch_size, 1))\n",
        "    D_fake_pred = self.D(D_fake_data)\n",
        "    G_loss = self.criterion(D_fake_pred, labels)\n",
        "    G_loss.backward()\n",
        "    self.G_optimizer.step()\n",
        "    return G_loss\n",
        "\n",
        "\n",
        "  def eval_step(self, epoch):\n",
        "    self.G.eval()\n",
        "    noise = torch.randn((1, noise_dim))\n",
        "    image = self.G(noise).resize(28, 28)\n",
        "    image = image.clamp(-1, 1).detach().cpu().numpy()\n",
        "    image = ((image + 1) * 127.5).astype('uint8')\n",
        "    Image.fromarray(image).save(os.path.join(self.fig_dir, 'fig_{}.png'.format(epoch)))"
      ],
      "metadata": {
        "id": "SrVMkV7p710c"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer()\n",
        "trainer.run()"
      ],
      "metadata": {
        "id": "DMUGbZb295nX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d73ca34-46ae-424b-c2db-e1a05e89d1f6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 1, G_loss = 0.9251, D_loss = 1.2264: 100%|██████████| 600/600 [00:38<00:00, 15.63it/s]\n",
            "Epoch: 2, G_loss = 0.9588, D_loss = 1.2638: 100%|██████████| 600/600 [00:38<00:00, 15.67it/s]\n",
            "Epoch: 3, G_loss = 0.6401, D_loss = 1.3696: 100%|██████████| 600/600 [00:38<00:00, 15.74it/s]\n",
            "Epoch: 4, G_loss = 1.0635, D_loss = 1.1437: 100%|██████████| 600/600 [00:38<00:00, 15.62it/s]\n",
            "Epoch: 5, G_loss = 0.7940, D_loss = 1.1742: 100%|██████████| 600/600 [00:38<00:00, 15.60it/s]\n",
            "Epoch: 6, G_loss = 1.4659, D_loss = 0.9097: 100%|██████████| 600/600 [00:38<00:00, 15.61it/s]\n",
            "Epoch: 7, G_loss = 1.3065, D_loss = 1.0650: 100%|██████████| 600/600 [00:38<00:00, 15.72it/s]\n",
            "Epoch: 8, G_loss = 1.1696, D_loss = 1.1303: 100%|██████████| 600/600 [00:39<00:00, 15.09it/s]\n",
            "Epoch: 9, G_loss = 1.2391, D_loss = 1.0899: 100%|██████████| 600/600 [00:43<00:00, 13.94it/s]\n",
            "Epoch: 10, G_loss = 1.0050, D_loss = 1.2161: 100%|██████████| 600/600 [00:44<00:00, 13.55it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate samples using trained generator\n",
        "\n",
        "G = Generator(noise_dim, 28 * 28)\n",
        "G.load_state_dict(torch.load('gen_weights.pth'))\n",
        "\n",
        "#TODO: load weights into model from gen_weights.pth\n",
        "#TODO: generate 8 fake samples and plot them\n",
        "samples = torch.randn((8, 100))\n",
        "\n",
        "gen = G(samples)\n",
        "gen = gen.reshape(8, -1).clamp(-1, 1).detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "DB3bjbIc-PuC"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen = ((gen.reshape(8, 28, 28)+1)*0.5*255).astype('uint8')"
      ],
      "metadata": {
        "id": "ZDsic3WID9nv"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen = np.concatenate(gen, axis=0)\n",
        "Image.fromarray(gen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "s7PYbFUYENaj",
        "outputId": "1dc11afb-46de-498c-ae6a-3c481b3c21fb"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x224 at 0x7FEABDDB89D0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ]
}